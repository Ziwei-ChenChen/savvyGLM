[{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"Generalized Linear Models (GLMs) widely used analyzing multivariate data non-normal responses. Iteratively Reweighted Least Squares (IRLS) algorithm main workhorse fitting models small medium-scale problems reduces estimation problem series Weighted Least Squares (WLS) subproblems, computationally less expensive solving full maximum likelihood optimization directly. However, IRLS can sensitive convergence issues—especially using standard Ordinary Least Squares (OLS) update iteration. cases model mis-specification high variability data, OLS estimator may yield significant estimation error. glm2 package improves upon standard glm incorporating step-halving strategy better handle convergence challenges. robust framework implemented glm.fit2 function. savvyGLM package, build robust framework provided glm2 package (function glm.fit2) replacing standard OLS update IRLS algorithm shrinkage estimator. rationale shrinkage estimation introduces small bias substantially reduce Mean Squared Error (MSE) OLS estimates, resulting reliable parameter estimates enhanced convergence stability. corresponding shrinkage paper can find Slab Shrinkage Linear Regression Estimation. Simulation studies real-data applications demonstrate replacing OLS update IRLS shrinkage estimator improves convergence overall performance GLM estimation compared traditional non-penalized implementation. summary, package modifies glm.fit2 glm2 : Leverage robust features, step-halving, already present glm2. Replace OLS update one several shrinkage estimators (e.g., St_ost, DSh_ost, SR_ost, GSR_ost, optionally Sh_ost). Employ parallelization multiple candidate methods specified. details, please see: Asimit, V., Chen, Z., Dimitrova, D., Xie, Y., & Zhang, Y. (2025). Shrinkage GLM Modeling.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"main-features","dir":"Articles","previous_headings":"Introduction","what":"Main Features","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"savvyGLM provides five classes shrinkage methods GLMs, although default four evaluated unless user explicitly includes Sh(since Sh time-consuming): Custom Optimization Methods: Implements shrinkage estimators (St_ost, DSh_ost, SR_ost, GSR_ost, optionally Sh_ost) replace standard OLS update IRLS. Flexible Model Choice: model_class argument allows users choose one shrinkage methods. default, \"St\", \"DSh\", \"SR\", \"GSR\" evaluated. Including \"Sh\" optional solving Sylvester equation required Sh_ost computationally intensive. Parallel Evaluation: multiple candidate methods specified, function evaluates parallel (use_parallel = TRUE) selects final model based lowest Akaike Information Criterion (AIC).","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"key-argument-and-output-summary","dir":"Articles","previous_headings":"Introduction","what":"Key Argument and Output Summary","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"vignette provides overview methods implemented savvyGLM demonstrates use simulated data real data. begin theoretical overview shrinkage class GLM IRLS, walk simulation examples illustrate apply savvyGLM method.","code":""},{"path":[]},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"shrinkage-estimators","dir":"Articles","previous_headings":"Theoretical Overview","what":"Shrinkage estimators","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"underlying optimization methods savvyGLM designed reduce theoretical mean square error introducing small bias yields substantial reduction variance. trade-leads reliable parameter estimates improved convergence properties Generalized Linear Models. , just provide table summary since detailed theoretical overview shrinkage estimators applied GLMs, please refer savvySh package, covers many shrinkage estimators used , context linear regression. methods savvyGLM extend ideas generalized linear models, ensuring IRLS updates incorporate shrinkage iteration.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"generalized-linear-model-and-its-irls-implementation","dir":"Articles","previous_headings":"Theoretical Overview","what":"Generalized Linear Model and its IRLS Implementation","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"GLM assumes response variable YY, defined set 𝒴⊆ℜ\\mathcal{Y} \\subseteq \\Re, related set covariates 𝐗\\mathbf{X} 𝒳⊆ℜd\\mathcal{X} \\subseteq \\Re{^d}. conditional distribution YY belongs exponential dispersion family, probability density mass function fY(y;θ,ϕ)=exp{θy−b(θ)(ϕ)+c(y,ϕ)}, f_Y(y; \\theta, \\phi) \\;=\\; \\exp\\left\\{\\frac{\\theta\\,y - b(\\theta)}{(\\phi)} \\;+\\; c(y, \\phi)\\right\\}, θ\\theta canonical parameter, ϕ\\phi dispersion parameter, aa, bb, cc known functions. mean YY linked linear predictor ηi=𝐱i⊤𝛃\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta} link function gg, 𝔼[Yi∣𝐗i=𝐱i]=h(𝐱i⊤𝛃), \\mathbb{E}[Y_i \\mid \\mathbf{X}_i = \\mathbf{x}_i] \\;=\\; h\\left(\\mathbf{x}_i^\\top \\boldsymbol{\\beta}\\right), h=g−1h = g^{-1} inverse link. canonical link, h(⋅)=b′(⋅)h(\\cdot) = b^\\prime(\\cdot). independent sample {(yi,𝐱i)}=1n\\left\\{(y_i, \\mathbf{x}_i)\\right\\}_{=1}^n, log-likelihood 𝛃\\boldsymbol{\\beta} can written ℓ(𝛃)=∑=1nθiyi−b(θi)(ϕ)+c(yi,ϕ), \\ell(\\boldsymbol{\\beta})  \\;=\\; \\sum_{=1}^n \\frac{\\theta_i\\,y_i \\;-\\; b(\\theta_i)}{(\\phi)} \\;+\\; c\\left(y_i, \\phi\\right), θi=(b′)−1∘h(𝐱i⊤𝛃)\\theta_i = (b^\\prime)^{-1}\\circ\\, h\\left(\\mathbf{x}_i^\\top \\boldsymbol{\\beta}\\right). Maximizing log-likelihood equivalent minimizing following objective function, 𝒞(𝛃)=−∑=1n(θiyi−b(θi)). \\mathcal{C}(\\boldsymbol{\\beta})  \\;=\\; -\\sum_{=1}^n \\left(\\theta_i\\,y_i \\;-\\; b(\\theta_i)\\right). Taking derivative 𝒞(𝛃)\\mathcal{C}(\\boldsymbol{\\beta}) respect 𝛃\\boldsymbol{\\beta} leads -called normal equations, can solved iteratively. particular, IRLS algorithm reformulates iteration WLS problem: 𝛃̂(t+1)=argmin𝛃(𝐳(t)−𝐗𝛃)⊤𝐖(t)(𝐳(t)−𝐗𝛃), \\widehat{\\boldsymbol{\\beta}}^{(t+1)}  \\;=\\; \\underset{\\boldsymbol{\\beta}}{\\mathrm{arg\\,min}} \\;\\left(\\mathbf{z}^{(t)} - \\mathbf{X}\\,\\boldsymbol{\\beta}\\right)^\\top \\mathbf{W}^{(t)} \\left(\\mathbf{z}^{(t)} - \\mathbf{X}\\,\\boldsymbol{\\beta}\\right), 𝐖(t)\\mathbf{W}^{(t)} diagonal matrix weights 𝐳(t)\\mathbf{z}^{(t)} pseudo-response iteration tt. Specifically, 𝐖(t)=diag((h′(ηi(t)))2/V(μi(t))),𝐳i(t)=ηi(t)+yi−μi(t)h′(ηi(t)), \\mathbf{W}^{(t)}  \\;=\\; \\mathrm{diag}\\left(\\left(h^\\prime(\\eta_i^{(t)})\\right)^2 / V\\left(\\mu_i^{(t)}\\right)\\right), \\quad \\mathbf{z}_i^{(t)}  \\;=\\; \\eta_i^{(t)} \\;+\\; \\frac{y_i - \\mu_i^{(t)}}{h^\\prime(\\eta_i^{(t)})}, μi(t)=h(ηi(t))\\mu_i^{(t)} = h(\\eta_i^{(t)}) ηi(t)=𝐱i⊤𝛃̂(t)\\eta_i^{(t)} = \\mathbf{x}_i^\\top \\widehat{\\boldsymbol{\\beta}}^{(t)}. , V(μi)V(\\mu_i) variance function determined exponential family, h′h^\\prime derivative inverse link. iterating WLS problem convergence (maximum number iterations reached), IRLS provides maximum likelihood estimates GLM parameters. savvyGLM, WLS updates enhanced applying shrinkage estimators (St_ost, DSh_ost, SR_ost, GSR_ost}, orSh_ost`) iteration, thereby improving estimation accuracy convergence stability.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"simulation-examples","dir":"Articles","previous_headings":"","what":"Simulation Examples","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"section presents simulation studies compare performance shrinkage estimators implemented savvyGLM package. compare standard IRLS update (implemented glm.fit2) various shrinkage methods implemented savvyGLM measuring L2L_2 distance estimated true coefficients. Lower L2L_2 values indicate better estimation accuracy. following data-generating processes (DGPs) considered logistic regression (LR), Poisson, Gamma GLMs log link sqrt link: Covariate Matrix: covariate matrix 𝐗∈ℜn×p\\mathbf{X} \\\\Re^{n \\times p} drawn multivariate normal distribution mean zero, unit variances, Toeplitz covariance matrix Σ\\Sigma Cov(Xi,j,Xk,j)=ρ|−k|\\text{Cov}(X_{,j}, X_{k,j}) = \\rho^{|-k|} ρ∈(−1,1)\\rho \\(-1,1). True Coefficients: true regression coefficients βj\\beta_j set alternate sign increase magnitude (e.g., 1,−1,2,−2,…1, -1, 2, -2, \\dots LR logit link). Poisson Gamma GLMs log link, smaller scaling used avoid numerical issues. Response Generation: LR: Compute linear predictor: ηi=β0+∑j=1pβjxij\\eta_i = \\beta_0 + \\sum_{j=1}^p \\beta_j x_{ij} generate Yi∼Binomial(1,11+e−ηi)Y_i \\sim \\text{Binomial}\\left(1, \\frac{1}{1+e^{-\\eta_i}}\\right). Poisson GLM:Two link functions considered:log link: μi=eηi\\mu_i = e^{\\eta_i}; sqrt link: μi=ηi2\\mu_i = \\eta_i^2. , generate Yi∼Poisson(μi)Y_i \\sim \\text{Poisson}(\\mu_i). Gamma GLM: Similarly, use μi=eηi\\mu_i = e^{\\eta_i} (log link) μi=ηi2\\mu_i = \\eta_i^2 (sqrt link), generate YiY_i Gamma distribution mean μi\\mu_i. scenario, fit GLM using standard IRLS update (.e., OLS-based) shrinkage-based IRLS update implemented savvyGLM. performance assessed using L2L_2 distance estimated true coefficients. Tables comparing distances relevant diagnostics provided illustrate benefits shrinkage approach. simulation studies aims demonstrate replacing OLS update shrinkage estimators IRLS algorithm improves convergence estimation accuracy, especially challenging settings multicollinearity extreme response values. Note: Due differences underlying libraries random number generation implementations (e.g., BLAS/LAPACK RNG behavior), data generated functions like mvrnorm may differ slightly Windows macOS/Linux, even seed.","code":""},{"path":[]},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"balanced-data","dir":"Articles","previous_headings":"Simulation Examples > Logistic Regression","what":"Balanced Data","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"simulation, balanced binary responses generated using logit link. Covariates sampled multivariate normal distribution Toeplitz covariance matrix determined various correlation coefficients. ensure balanced dataset, larger dataset first generated, subset selected achieve roughly equal proportions 0’s 1’s. fit models using standard GLM (via glm.fit2) shrinkage-based GLM (via savvy_glm.fit2in savvyGLM package). summary table produced compare distances across different ρ\\rho values. L2 Distance Estimated True Coefficients (Balanced LR)","code":"# Load packages library(savvyGLM) library(MASS) library(glm2) #>  #> Attaching package: 'glm2' #> The following object is masked from 'package:MASS': #>  #>     crabs library(CVXR) #>  #> Attaching package: 'CVXR' #> The following object is masked from 'package:MASS': #>  #>     huber #> The following object is masked from 'package:stats': #>  #>     power library(knitr)  set.seed(123) n_val <- 500 p_val <- 25 rho_vals <- c(-0.75, -0.5, 0, 0.5, 0.75) mu_val <- 0 target_proportion <- 0.5 control_list <- list(maxit = 250, epsilon = 1e-6, trace = FALSE) family_type <- binomial(link = \"logit\")  sigma.rho <- function(rho_val, p_val) {   rho_val ^ abs(outer(1:p_val, 1:p_val, \"-\")) }  theta_func <- function(p_val) {   sgn <- rep(c(1, -1), length.out = p_val)   mag <- ceiling(seq_len(p_val) / 2)   sgn * mag }  findStartingValues <- function(x, y) {   beta <- Variable(ncol(x))   eta <- x %*% beta   g_y <- (y + 0.5) / 2   logit_g_y <- log(g_y / (1 - g_y))   objective <- Minimize(sum_squares(logit_g_y - eta))   problem <- Problem(objective)   result <- solve(problem)   as.numeric(result$getValue(beta)) }  model_names <- c(\"OLS\", \"SR\", \"GSR\", \"St\", \"DSh\", \"Sh\") l2_matrix <- matrix(NA, nrow = length(model_names), ncol = length(rho_vals),                     dimnames = list(model_names, paste0(\"rho=\", rho_vals))) for (j in seq_along(rho_vals)) {   rho_val <- rho_vals[j]   Sigma <- sigma.rho(rho_val, p_val)   n_val_large <- n_val * 10      X_large <- mvrnorm(n_val_large, mu = rep(mu_val, p_val), Sigma = Sigma)   X_large_intercept <- cbind(1, X_large)   beta_true <- theta_func(p_val + 1)   mu_y_large <- as.vector(1 / (1 + exp(-X_large_intercept %*% beta_true)))   y_large <- rbinom(n = n_val_large, size = 1, prob = mu_y_large)    y_zero_indices <- which(y_large == 0)[1:round(n_val * target_proportion)]   y_one_indices <- which(y_large == 1)[1:(n_val - round(n_val * target_proportion))]   final_indices <- c(y_zero_indices, y_one_indices)   X_final <- X_large_intercept[final_indices, ]   y_final <- y_large[final_indices]   starting_values <- findStartingValues(X_final, y_final)      fit_ols <- glm.fit2(X_final, y_final, start = starting_values,                       control = control_list, family = family_type)   l2_matrix[\"OLS\", j] <- norm(fit_ols$coefficients - beta_true, type = \"2\")    for (m in model_names[-1]) {     fit <- savvy_glm.fit2(X_final, y_final, model_class = m,                            start = starting_values, control = control_list, family = family_type)     l2_matrix[m, j] <- norm(fit$coefficients - beta_true, type = \"2\")   } } l2_table <- as.data.frame(l2_matrix) kable(l2_table, digits = 4, caption = \"L2 Distance Between Estimated and True Coefficients (Balanced LR)\")"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"imbalanced-data","dir":"Articles","previous_headings":"Simulation Examples > Logistic Regression","what":"Imbalanced Data","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"imbalanced LR, simulation settings similar except target proportion negative class reduced (example, 5% responses 0’s). results skewed binary response, allows us evaluate robustness shrinkage estimators class imbalance. , models fit using standard GLM various shrinkage-based GLM. summary table produced compare distances across different ρ\\rho values. L2 Distance Estimated True Coefficients (Imbalanced LR)","code":"# Load packages library(savvyGLM) library(MASS) library(glm2) library(CVXR) library(knitr)  set.seed(123) n_val <- 500 p_val <- 25 rho_vals <- c(-0.75, -0.5, 0, 0.5, 0.75) mu_val <- 0 target_proportion <- 0.05 control_list <- list(maxit = 250, epsilon = 1e-6, trace = FALSE) family_type <- binomial(link = \"logit\")  sigma.rho <- function(rho_val, p_val) {   rho_val ^ abs(outer(1:p_val, 1:p_val, \"-\")) }  theta_func <- function(p_val) {   sgn <- rep(c(1, -1), length.out = p_val)   mag <- ceiling(seq_len(p_val) / 2)   sgn * mag }  findStartingValues <- function(x, y) {   beta <- Variable(ncol(x))   eta <- x %*% beta   g_y <- (y + 0.5) / 2   logit_g_y <- log(g_y / (1 - g_y))   objective <- Minimize(sum_squares(logit_g_y - eta))   problem <- Problem(objective)   result <- solve(problem)   as.numeric(result$getValue(beta)) }  model_names <- c(\"OLS\", \"SR\", \"GSR\", \"St\", \"DSh\", \"Sh\") l2_matrix <- matrix(NA, nrow = length(model_names), ncol = length(rho_vals),                     dimnames = list(model_names, paste0(\"rho=\", rho_vals))) for (j in seq_along(rho_vals)) {   rho_val <- rho_vals[j]   Sigma <- sigma.rho(rho_val, p_val)   n_val_large <- n_val * 10      X_large <- mvrnorm(n_val_large, mu = rep(mu_val, p_val), Sigma = Sigma)   X_large_intercept <- cbind(1, X_large)   beta_true <- theta_func(p_val + 1)   mu_y_large <- as.vector(1 / (1 + exp(-X_large_intercept %*% beta_true)))   y_large <- rbinom(n = n_val_large, size = 1, prob = mu_y_large)    y_zero_indices <- which(y_large == 0)[1:round(n_val * target_proportion)]   y_one_indices <- which(y_large == 1)[1:(n_val - round(n_val * target_proportion))]   final_indices <- c(y_zero_indices, y_one_indices)   X_final <- X_large_intercept[final_indices, ]   y_final <- y_large[final_indices]   starting_values <- findStartingValues(X_final, y_final)      fit_ols <- glm.fit2(X_final, y_final, start = starting_values,                       control = control_list, family = family_type)   l2_matrix[\"OLS\", j] <- norm(fit_ols$coefficients - beta_true, type = \"2\")    for (m in model_names[-1]) {     fit <- savvy_glm.fit2(X_final, y_final, model_class = m,                            start = starting_values, control = control_list, family = family_type)     l2_matrix[m, j] <- norm(fit$coefficients - beta_true, type = \"2\")   } } l2_table <- as.data.frame(l2_matrix) kable(l2_table, digits = 4, caption = \"L2 Distance Between Estimated and True Coefficients (Imbalanced LR)\")"},{"path":[]},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"log-link-function","dir":"Articles","previous_headings":"Simulation Examples > Poisson GLMs","what":"Log Link Function","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"Poisson GLMs log link, mean response modeled μ=exp(η)\\mu = \\exp(\\eta) η=Xinterceptβtrue\\eta = X_{\\text{intercept}} \\, \\beta_{\\text{true}}. simulation, covariates generated multivariate normal distribution Toeplitz covariance matrix. responses simulated Poisson distribution rate μ=exp(η)\\mu = \\exp(\\eta). fit models using standard GLM (via glm.fit2) shrinkage-based GLM (via savvy_glm.fit2in savvyGLM package). summary table produced compare distances across different ρ\\rho values. L2 Distance Estimated True Coefficients (log link Poisson GLM)","code":"# Load packages library(savvyGLM) library(MASS) library(glm2) library(CVXR) library(knitr)  set.seed(123) n_val <- 500 p_val <- 25 rho_vals <- c(-0.75, -0.5, 0, 0.5, 0.75) mu_val <- 0 control_list <- list(maxit = 250, epsilon = 1e-6, trace = FALSE) family_type <- poisson(link = \"log\")  sigma.rho <- function(rho_val, p_val) {   rho_val ^ abs(outer(1:p_val, 1:p_val, \"-\")) }  theta_func <- function(p_val) {   base_increment <- 0.1   growth_rate <- 0.95    betas <- base_increment * (growth_rate ^ seq(from = 0, length.out = ceiling(p_val / 2)))   betas <- rep(betas, each = 2)[1:p_val]   signs <- rep(c(1, -1), length.out = p_val)   betas <- betas * signs   return(betas) }  findStartingValues <- function(x, y) {   beta <- Variable(ncol(x))   eta <- x %*% beta   objective <- Minimize(sum_squares(log(y + 0.1) - eta))   problem <- Problem(objective)   result <- solve(problem)   starting_values <- as.numeric(result$getValue(beta))   return(starting_values) }  model_names <- c(\"OLS\", \"SR\", \"GSR\", \"St\", \"DSh\", \"Sh\") l2_matrix <- matrix(NA, nrow = length(model_names), ncol = length(rho_vals),                     dimnames = list(model_names, paste0(\"rho=\", rho_vals))) for (j in seq_along(rho_vals)) {   rho_val <- rho_vals[j]   Sigma <- sigma.rho(rho_val, p_val)      X <- mvrnorm(n_val, mu = rep(mu_val, p_val), Sigma = Sigma)   X_intercept <- cbind(1, X)   beta_true <- theta_func(p_val + 1)   mu_y <- as.vector(exp(X_intercept %*% beta_true))   y <- rpois(n_val, lambda = mu_y)   starting_values <- findStartingValues(X_intercept, y)      fit_ols <- glm.fit2(X_intercept, y, start = starting_values,                       control = control_list, family = family_type)   l2_matrix[\"OLS\", j] <- norm(fit_ols$coefficients - beta_true, type = \"2\")    for (m in model_names[-1]) {     fit <- savvy_glm.fit2(X_intercept, y, model_class = m,                            start = starting_values, control = control_list, family = family_type)     l2_matrix[m, j] <- norm(fit$coefficients - beta_true, type = \"2\")   } } l2_table <- as.data.frame(l2_matrix) kable(l2_table, digits = 4, caption = \"L2 Distance Between Estimated and True Coefficients (log link for Poisson GLM)\")"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"sqrt-link-function","dir":"Articles","previous_headings":"Simulation Examples > Poisson GLMs","what":"sqrt Link Function","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"Poisson GLM sqrt link, mean response defined μ=η2\\mu = \\eta^2 η=Xinterceptβtrue\\eta = X_{\\text{intercept}} \\, \\beta_{\\text{true}}. simulation procedure similar log link case; however, responses generated Poission distribution λ\\lambdaμ=η2\\mu=\\eta^2. address potential numerical issues (non-positive responses). Models fit using standard GLM (via glm.fit2) shrinkage-based GLM (via savvy_glm.fit2in savvyGLM package). summary table produced compare distances across different ρ\\rho values. L2 Distance Estimated True Coefficients (sqrt link Poisson GLM)","code":"# Load packages library(savvyGLM) library(MASS) library(glm2) library(CVXR) library(knitr)  set.seed(123) n_val <- 500 p_val <- 25 rho_vals <- c(-0.75, -0.5, 0, 0.5, 0.75) mu_val <- 0 control_list <- list(maxit = 250, epsilon = 1e-6, trace = FALSE) family_type <- poisson(link = \"sqrt\")  sigma.rho <- function(rho_val, p_val) {   rho_val ^ abs(outer(1:p_val, 1:p_val, \"-\")) }  theta_func <- function(p_val) {   sgn <- rep(c(1, -1), length.out = p_val)   mag <- ceiling(seq_len(p_val) / 2)   sgn * mag }  findStartingValues <- function(x, y, epsilon = 1e-6) {   beta <- Variable(ncol(x))   eta <- x %*% beta   objective <- Minimize(sum_squares(sqrt(y + 0.1) - eta))   constraints <- list(eta >= epsilon)   problem <- Problem(objective, constraints)   result <- solve(problem)   starting_values <- as.numeric(result$getValue(beta))   return(starting_values) }  model_names <- c(\"OLS\", \"SR\", \"GSR\", \"St\", \"DSh\", \"Sh\") l2_matrix <- matrix(NA, nrow = length(model_names), ncol = length(rho_vals),                     dimnames = list(model_names, paste0(\"rho=\", rho_vals))) for (j in seq_along(rho_vals)) {   rho_val <- rho_vals[j]   Sigma <- sigma.rho(rho_val, p_val)      X <- mvrnorm(n_val, mu = rep(mu_val, p_val), Sigma = Sigma)   X_intercept <- cbind(1, X)   beta_true <- theta_func(p_val + 1)   mu_y <- as.vector((X_intercept %*% beta_true)^2)   y <- rpois(n_val, lambda = mu_y)   starting_values <- findStartingValues(X_intercept, y)      fit_ols <- glm.fit2(X_intercept, y, start = starting_values,                       control = control_list, family = family_type)   l2_matrix[\"OLS\", j] <- norm(fit_ols$coefficients - beta_true, type = \"2\")    for (m in model_names[-1]) {     fit <- savvy_glm.fit2(X_intercept, y, model_class = m,                            start = starting_values, control = control_list, family = family_type)     l2_matrix[m, j] <- norm(fit$coefficients - beta_true, type = \"2\")   } } l2_table <- as.data.frame(l2_matrix) kable(l2_table, digits = 4, caption = \"L2 Distance Between Estimated and True Coefficients (sqrt link for Poisson GLM)\")"},{"path":[]},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"log-link-function-1","dir":"Articles","previous_headings":"Simulation Examples > Gamma GLMs","what":"log Link Function","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"Gamma GLMs log link, mean response given μ=exp(η)\\mu = \\exp(\\eta) η=Xinterceptβtrue\\eta = X_{\\text{intercept}} \\, \\beta_{\\text{true}}. Covariates generated , responses drawn Gamma distribution shape μ=exp(η)\\mu =\\exp(\\eta). retry mechanism used ensure simulated responses positive, required Gamma model. Models fit using standard GLM (via glm.fit2) shrinkage-based GLM (via savvy_glm.fit2in savvyGLM package). summary table produced compare distances across different ρ\\rho values. L2 Distance Estimated True Coefficients (log link Gamma GLM)","code":"# Load packages library(savvyGLM) library(MASS) library(glm2) library(CVXR) library(knitr)  set.seed(123) n_val <- 500 p_val <- 25 rho_vals <- c(-0.75, -0.5, 0, 0.5, 0.75) mu_val <- 0 control_list <- list(maxit = 250, epsilon = 1e-6, trace = FALSE) family_type <- Gamma(link = \"log\")  sigma.rho <- function(rho_val, p_val) {   rho_val ^ abs(outer(1:p_val, 1:p_val, \"-\")) }  theta_func <- function(p_val) {   base_increment <- 0.1   growth_rate <- 0.95    betas <- base_increment * (growth_rate ^ seq(from = 0, length.out = ceiling(p_val / 2)))   betas <- rep(betas, each = 2)[1:p_val]   signs <- rep(c(1, -1), length.out = p_val)   betas <- betas * signs   return(betas) }  findStartingValues <- function(x, y) {   beta <- Variable(ncol(x))   eta <- x %*% beta   objective <- Minimize(sum_squares(log(y + 0.1) - eta))   problem <- Problem(objective)   result <- solve(problem)   starting_values <- as.numeric(result$getValue(beta))   return(starting_values) }  model_names <- c(\"OLS\", \"SR\", \"GSR\", \"St\", \"DSh\", \"Sh\") l2_matrix <- matrix(NA, nrow = length(model_names), ncol = length(rho_vals),                     dimnames = list(model_names, paste0(\"rho=\", rho_vals))) for (j in seq_along(rho_vals)) {   rho_val <- rho_vals[j]   Sigma <- sigma.rho(rho_val, p_val)      X <- mvrnorm(n_val, mu = rep(mu_val, p_val), Sigma = Sigma)   X_intercept <- cbind(1, X)   beta_true <- theta_func(p_val + 1)   mu_y <- as.vector(exp(X_intercept %*% beta_true))   y <-  rgamma(n_val, shape = mu_y, scale = 1)   retry_count <- 0   while(any(y <= 0) && retry_count < 100) {     bad_idx <- which(y <= 0)     y[bad_idx] <- rgamma(length(bad_idx), shape = mu_y[bad_idx], scale = 1)     retry_count <- retry_count + 1   }   starting_values <- findStartingValues(X_intercept, y)      fit_ols <- glm.fit2(X_intercept, y, start = starting_values,                       control = control_list, family = family_type)   l2_matrix[\"OLS\", j] <- norm(fit_ols$coefficients - beta_true, type = \"2\")    for (m in model_names[-1]) {     fit <- savvy_glm.fit2(X_intercept, y, model_class = m,                            start = starting_values, control = control_list, family = family_type)     l2_matrix[m, j] <- norm(fit$coefficients - beta_true, type = \"2\")   } } l2_table <- as.data.frame(l2_matrix) kable(l2_table, digits = 4, caption = \"L2 Distance Between Estimated and True Coefficients (log link for Gamma GLM)\")"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"sqrt-link-function-1","dir":"Articles","previous_headings":"Simulation Examples > Gamma GLMs","what":"sqrt Link Function","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"Gamma GLMs sqrt link, mean response modeled μ=η2\\mu = \\eta^2 η=Xinterceptβtrue\\eta = X_{\\text{intercept}} \\, \\beta_{\\text{true}}. Covariates generated , responses drawn Gamma distribution shape μ=η2\\mu =\\eta^2, including retry mechanism ensure response values positive. Fitting models using standard GLM (via glm.fit2) shrinkage-based GLM (via savvy_glm.fit2in savvyGLM package). summary table produced compare distances across different ρ\\rho values. L2 Distance Estimated True Coefficients (sqrt link Gamma GLM)","code":"# Load packages library(savvyGLM) library(MASS) library(glm2) library(CVXR) library(knitr)  set.seed(123) n_val <- 500 p_val <- 25 rho_vals <- c(-0.75, -0.5, 0, 0.5, 0.75) mu_val <- 0 control_list <- list(maxit = 250, epsilon = 1e-6, trace = FALSE) family_type <- Gamma(link = \"sqrt\")  sigma.rho <- function(rho_val, p_val) {   rho_val ^ abs(outer(1:p_val, 1:p_val, \"-\")) }  theta_func <- function(p_val) {   sgn <- rep(c(1, -1), length.out = p_val)   mag <- ceiling(seq_len(p_val) / 2)   sgn * mag }  findStartingValues <- function(x, y, epsilon = 1e-6) {   beta <- Variable(ncol(x))   eta <- x %*% beta   objective <- Minimize(sum_squares(sqrt(y + 0.1) - eta))   constraints <- list(eta >= epsilon)   problem <- Problem(objective, constraints)   result <- solve(problem)   starting_values <- as.numeric(result$getValue(beta))   return(starting_values) }  model_names <- c(\"OLS\", \"SR\", \"GSR\", \"St\", \"DSh\", \"Sh\") l2_matrix <- matrix(NA, nrow = length(model_names), ncol = length(rho_vals),                     dimnames = list(model_names, paste0(\"rho=\", rho_vals))) for (j in seq_along(rho_vals)) {   rho_val <- rho_vals[j]   Sigma <- sigma.rho(rho_val, p_val)      X <- mvrnorm(n_val, mu = rep(mu_val, p_val), Sigma = Sigma)   X_intercept <- cbind(1, X)   beta_true <- theta_func(p_val + 1)   mu_y <- as.vector((X_intercept %*% beta_true)^2)   y <- rgamma(n_val, shape = mu_y, scale = 1)   retry_count <- 0   while(any(y <= 0) && retry_count < 100) {     bad_idx <- which(y <= 0)     y[bad_idx] <- rgamma(length(bad_idx), shape = mu_y[bad_idx], scale = 1)     retry_count <- retry_count + 1   }   starting_values <- findStartingValues(X_intercept, y)      fit_ols <- glm.fit2(X_intercept, y, start = starting_values,                       control = control_list, family = family_type)   l2_matrix[\"OLS\", j] <- norm(fit_ols$coefficients - beta_true, type = \"2\")    for (m in model_names[-1]) {     fit <- savvy_glm.fit2(X_intercept, y, model_class = m,                            start = starting_values, control = control_list, family = family_type)     l2_matrix[m, j] <- norm(fit$coefficients - beta_true, type = \"2\")   } } l2_table <- as.data.frame(l2_matrix) kable(l2_table, digits = 4, caption = \"L2 Distance Between Estimated and True Coefficients (sqrt link for Gamma GLM)\")"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"real-data-analysis","dir":"Articles","previous_headings":"","what":"Real Data Analysis","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"section, evaluate performance Gamma GLM estimation methods using real flood insurance data three states: Florida (FL), Texas (TX), Louisiana (LA). dataset covers period 2014 2023 includes claims National Flood Insurance Programme (NFIP). state (e.g., Florida (FL) Louisiana (LA)), data provided , can download NFIP follow preprocess steps provided paper. year, dataset split 70% training set 30% test set. Models fitted using standard GLM (via glm.fit2) several shrinkage-based GLM (via savvy_glm.fit2 model classes SR, GSR, St, DSh, optionally Sh) using two different link functions: Gamma GLMs log link, mean response modeled μ=exp(η)\\mu = \\exp(\\eta). Gamma GLMs sqrt link, mean response modeled μ=η2\\mu = \\eta^2. replication, MSE test set computed. shrinkage-based GLM, calculate ratio MSE Ratio=MSEBaseline (OLS)MSEShrinkage. \\text{MSE Ratio} = \\frac{\\text{MSE}_{\\text{Baseline (OLS)}}}{\\text{MSE}_{\\text{Shrinkage}}}. ratio greater one indicates shrinkage-based GLM achieved lower MSE (.e., superior performance) compared standard update. process repeated multiple times (e.g., N=100N=100 replications per year), average ratio computed model year. , just provide two cases detailed account full data processing evaluation procedures, please refer main paper.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"fl-dataset-with-log-link-function","dir":"Articles","previous_headings":"Real Data Analysis","what":"FL dataset with log Link Function","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"","code":"# Load required packages library(savvyGLM) library(MASS) library(glm2) library(CVXR) library(caret) library(knitr)  set.seed(1234) years <- 2014:2015 model_names <- c(\"OLS\", \"SR\", \"GSR\", \"St\", \"DSh\") N <- 10 control_list <- list(maxit = 250, epsilon = 1e-6, trace = FALSE) family_type <- Gamma(link = \"log\")  Evaluation_results <- matrix(NA, nrow = length(model_names), ncol = length(years),                              dimnames = list(model_names, years))  findStartingValues <- function(x, y) {   beta <- Variable(ncol(x))   eta <- x %*% beta   objective <- Minimize(sum_squares(log(y + 0.1) - eta))   problem <- Problem(objective)   result <- solve(problem)   starting_values <- as.numeric(result$getValue(beta))   return(starting_values) }  calculate_mse <- function(true_values, predicted_values) {   mean((true_values - predicted_values)^2) }  for (yr in years) {   cat(\"Processing year:\", yr, \"\\n\")   filename <- sprintf(\"FL_data_%d.csv\", yr)   data_year <- read.csv(filename, header = TRUE, stringsAsFactors = FALSE)      ratio_mat <- matrix(NA, nrow = N, ncol = length(model_names)-1)   colnames(ratio_mat) <- model_names[-1]   for (i in 1:N) {     set.seed(yr * 1000 + i)     train_index <- createDataPartition(data_year[, 1], p = 0.7, list = FALSE)     train_data <- data_year[train_index, ]     test_data <- data_year[-train_index, ]          X_train <- as.matrix(train_data[, -1])     y_train <- train_data[, 1]     X_test <- as.matrix(test_data[, -1])     y_test <- test_data[, 1]     X_train_int <- cbind(1, X_train)     X_test_int <- cbind(1, X_test)     starting_values <- findStartingValues(X_train_int, y_train)        model_glm2 <- glm.fit2(X_train_int, y_train, start = starting_values,                            control = control_list, family = family_type)     y_pred_glm2 <- exp(X_test_int %*% model_glm2$coefficients)     mse_ols <- calculate_mse(y_test, y_pred_glm2)     for (m in model_names[-1]) {       model_savvy <- savvy_glm.fit2(X_train_int, y_train, model_class = m,                                       start = starting_values, control = control_list, family = family_type)       y_pred <- exp(X_test_int %*% model_savvy$coefficients)       mse_savvy <- calculate_mse(y_test, y_pred)       ratio_mat[i, m] <- mse_ols / mse_savvy     }   }   avg_ratios <- c(1, colMeans(ratio_mat, na.rm = TRUE))   Evaluation_results[, as.character(yr)] <- avg_ratios } Evaluation_results_df <- as.data.frame(Evaluation_results) kable(Evaluation_results_df, digits = 4,       caption = \"Average MSE Ratio (OLS / Shrinkage) for Each Year (Gamma GLM with Log Link)\")"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/articles/savvyGLM.html","id":"la-dataset-with-sqrt-link-function","dir":"Articles","previous_headings":"Real Data Analysis","what":"LA dataset with sqrt Link Function","title":"savvyGLM: Shrinkage Methods for Generalized Linear Models","text":"","code":"# Load required packages library(savvyGLM) library(MASS) library(glm2) library(CVXR) library(caret) library(knitr)  set.seed(1234) years <- 2014:2023 model_names <- c(\"OLS\", \"SR\", \"GSR\", \"St\", \"DSh\") N <- 100 control_list <- list(maxit = 250, epsilon = 1e-6, trace = FALSE) family_type <- Gamma(link = \"sqrt\")  Evaluation_results <- matrix(NA, nrow = length(model_names), ncol = length(years),                              dimnames = list(model_names, years))  findStartingValues <- function(x, y, epsilon = 1e-6) {   beta <- Variable(ncol(x))   eta <- x %*% beta   objective <- Minimize(sum_squares(sqrt(y + 0.1) - eta))   constraints <- list(eta >= epsilon)   problem <- Problem(objective, constraints)   result <- solve(problem)   starting_values <- as.numeric(result$getValue(beta))   return(starting_values) }  calculate_mse <- function(true_values, predicted_values) {   mean((true_values - predicted_values)^2) }  for (yr in years) {   cat(\"Processing year:\", yr, \"\\n\")   filename <- sprintf(\"LA_data_%d.csv\", yr)   data_year <- read.csv(filename, header = TRUE, stringsAsFactors = FALSE)      ratio_mat <- matrix(NA, nrow = N, ncol = length(model_names)-1)   colnames(ratio_mat) <- model_names[-1]   for (i in 1:N) {     set.seed(yr * 1000 + i)     train_index <- createDataPartition(data_year[, 1], p = 0.7, list = FALSE)     train_data <- data_year[train_index, ]     test_data <- data_year[-train_index, ]          X_train <- as.matrix(train_data[, -1])     y_train <- train_data[, 1]     X_test <- as.matrix(test_data[, -1])     y_test <- test_data[, 1]     X_train_int <- cbind(1, X_train)     X_test_int <- cbind(1, X_test)     starting_values <- findStartingValues(X_train_int, y_train)        model_glm2 <- glm.fit2(X_train_int, y_train, start = starting_values,                            control = control_list, family = family_type)     y_pred_glm2 <- (X_test_int %*% model_glm2$coefficients)^2     mse_ols <- calculate_mse(y_test, y_pred_glm2)     for (m in model_names[-1]) {       model_savvy <- savvy_glm.fit2(X_train_int, y_train, model_class = m,                                       start = starting_values, control = control_list, family = family_type)       y_pred <- exp(X_test_int %*% model_savvy$coefficients)       mse_savvy <- calculate_mse(y_test, y_pred)       ratio_mat[i, m] <- mse_ols / mse_savvy     }   }   avg_ratios <- c(1, colMeans(ratio_mat, na.rm = TRUE))   Evaluation_results[, as.character(yr)] <- avg_ratios } Evaluation_results_df <- as.data.frame(Evaluation_results) kable(Evaluation_results_df, digits = 4,       caption = \"Average MSE Ratio (OLS / Shrinkage) for Each Year (Gamma GLM with Log Link)\")"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ziwei Chen. Author, maintainer. Vali Asimit. Author.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chen Z, Asimit V (2025). savvyGLM: Generalized Linear Models Slab Shrinkage Estimators. R package version 0.1.0, https://Ziwei-ChenChen.github.io/savvyGLM.","code":"@Manual{,   title = {savvyGLM: Generalized Linear Models with Slab and Shrinkage Estimators},   author = {Ziwei Chen and Vali Asimit},   year = {2025},   note = {R package version 0.1.0},   url = {https://Ziwei-ChenChen.github.io/savvyGLM}, }"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/index.html","id":"savvyglm-shrinkage-methods-for-generalized-linear-models","dir":"","previous_headings":"","what":"Generalized Linear Models with Slab and Shrinkage Estimators","title":"Generalized Linear Models with Slab and Shrinkage Estimators","text":"savvyGLM package offers complete framework fitting shrinkage estimators generalized linear models (GLMs). integrates several shrinkage methods Iteratively Reweighted Least Squares (IRLS) algorithm improve convergence estimation accuracy, particularly standard maximum likelihood estimation challenged issues like multicollinearity high number predictors. Shrinkage estimators introduce small bias produces large reduction variance, making IRLS estimates reliable based solely traditional OLS update. details shrinkage estimators employed package, please refer Slab Shrinkage Linear Regression Estimation. package builds theoretical work discussed : Asimit, V., Chen, Z., Dimitrova, D., Xie, Y., & Zhang, Y. (2025). Shrinkage GLM Modeling. official documentation site available : https://Ziwei-ChenChen.github.io/savvyGLM interested applying shrinkage methods within linear regression, please refer companion package savvySh.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/index.html","id":"installation-guide","dir":"","previous_headings":"","what":"Installation Guide","title":"Generalized Linear Models with Slab and Shrinkage Estimators","text":"can install development version savvyGLM directly GitHub: installed, load package:","code":"remotes::install_github(\"Ziwei-ChenChen/savvyGLM\") library(savvyGLM)"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Generalized Linear Models with Slab and Shrinkage Estimators","text":"package supports several shrinkage approaches within IRLS algorithm, including: Stein Estimator (St): Applies single shrinkage factor coefficients. Diagonal Shrinkage (DSh): Applies separate shrinkage factors coefficient. Slab Regression (SR): Adds penalty shrinks solution along fixed direction. Generalized Slab Regression (GSR): Extends SR allowing shrinkage along multiple directions. Shrinkage Estimator (Sh): Uses full shrinkage matrix estimated solving Sylvester equation. method optional due higher computational cost. methods build robust features glm2 package—step-halving—enhance performance GLMs.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Generalized Linear Models with Slab and Shrinkage Estimators","text":"basic example shows solve common problem:","code":"set.seed(123) n <- 100 p <- 5  x <- matrix(rnorm(n * p), n, p) beta_true <- c(1, 0.5, -0.5, 1, -1) eta <- x %*% beta_true prob <- 1 / (1 + exp(-eta)) y <- rbinom(n, size = 1, prob = prob)  fit <- savvy_glm.fit2(   x      = cbind(1, x),    y      = y,   model_class = \"SR\",   family = binomial(link = \"logit\"),   control = glm.control(trace = TRUE) )  print(fit$coefficients) print(fit$chosen_fit)"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/index.html","id":"authors","dir":"","previous_headings":"","what":"Authors","title":"Generalized Linear Models with Slab and Shrinkage Estimators","text":"Ziwei Chen – ziwei.chen.3@citystgeorges.ac.uk Vali Asimit – asimit@citystgeorges.ac.uk","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Generalized Linear Models with Slab and Shrinkage Estimators","text":"package licensed MIT License.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm.fit2.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Linear Models Fitting with Slab and Shrinkage Estimators — savvy_glm.fit2","title":"Generalized Linear Models Fitting with Slab and Shrinkage Estimators — savvy_glm.fit2","text":"savvy_glm.fit2 modified version glm.fit stats package, incorporating custom optimization functions (St_ost, DSh_ost, SR_ost, GSR_ost, Sh_ost). user can specify preferred shrinkage model via model_class argument. user explicitly supply value model_class, function defaults running \"St\", \"DSh\", \"SR\", \"GSR\". user explicitly includes \"Sh\" (e.g. model_class = c(\"St\", \"DSh\", \"SR\", \"GSR\", \"Sh\")), Sh_ost also evaluated.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm.fit2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Linear Models Fitting with Slab and Shrinkage Estimators — savvy_glm.fit2","text":"","code":"savvy_glm.fit2(x, y, weights = rep(1, nobs),                         model_class = c(\"St\", \"DSh\", \"SR\", \"GSR\", \"Sh\"),                         start = NULL, etastart = NULL, mustart = NULL,                         offset = rep(0, nobs), family = gaussian(),                         control = list(), intercept = TRUE,                         use_parallel = TRUE)"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm.fit2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Linear Models Fitting with Slab and Shrinkage Estimators — savvy_glm.fit2","text":"x numeric matrix predictors. glm.fit. y numeric vector responses. glm.fit. weights optional vector weights used fitting process. glm.fit. model_class character vector specifying shrinkage model(s) used. Allowed values \"St\", \"DSh\", \"SR\", \"GSR\", \"Sh\". single value provided, method run. multiple values provided, function runs specified methods parallel returns best one based AIC. user explicitly supply value model_class, default c(\"St\", \"DSh\", \"SR\", \"GSR\") (.e. \"Sh\" considered). start Starting values parameters. glm.fit. etastart Starting values linear predictor. glm.fit. mustart Starting values mean. glm.fit. offset optional offset included model. glm.fit. family description error distribution link function used model. glm.fit. control list parameters controlling fitting process. glm.fit. intercept logical value indicating whether intercept included model. glm.fit. use_parallel Logical. TRUE, enables parallel execution fitting process. Defaults TRUE. Set FALSE serial execution.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm.fit2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Linear Models Fitting with Slab and Shrinkage Estimators — savvy_glm.fit2","text":"value returned savvy_glm.fit2 structure value returned glm.fit. includes following components: coefficients estimated coefficients. residuals working residuals, residuals final iteration IWLS fit. fitted.values fitted mean values, obtained transforming linear predictors inverse link function. R upper-triangular factor QR decomposition weighted model matrix. rank numeric rank fitted linear model. qr QR decomposition weighted model matrix. family family object used. linear.predictors final linear predictors. deviance deviance final model. aic AIC final model. null.deviance deviance null model. iter number iterations used. weights final weights used fitting process. prior.weights weights initially supplied. df.residual residual degrees freedom. df.null residual degrees freedom null model. y response vector used. converged logical value indicating whether IRLS iterations converged. boundary logical value indicating whether algorithm stopped boundary value. time time taken fitting process. chosen_fit name chosen fitting method based AIC.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm.fit2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Linear Models Fitting with Slab and Shrinkage Estimators — savvy_glm.fit2","text":"savvy_glm.fit2 extends glm.fit using custom optimization functions improve convergence properties iteratively reweighted least squares (IRLS) algorithm. user may choose run specific shrinkage method supplying single value model_class argument. multiple values provided (default used), function evaluates set custom optimization methods selects final model based Akaike Information Criterion (AIC). default, function considers St_ost, DSh_ost, SR_ost, GSR_ost (.e. model_class = c(\"St\", \"DSh\", \"SR\", \"GSR\")). user explicitly includes \"Sh\" model_class (example, model_class = c(\"St\", \"DSh\", \"SR\", \"GSR\", \"Sh\")), method Sh_ost also evaluated. fitting process starts initial parameter values iterates IRLS algorithm. iteration, coefficients computed using specified custom methods. method lowest AIC chosen final model, ensuring model converges best solution given data specified family. Custom Optimization Methods: Stein Estimator (St): Applies global multiplicative shrinkage factor coefficients. factor chosen reduce MSE based overall signal--noise ratio. Simple fast; works well coefficients can shrunk similarly. Diagonal Shrinkage (DSh): Extends St approach assigning separate shrinkage factor coefficient. factor computed coefficient size associated variance. flexible St, especially coefficients vary scale importance. Generalized Slab Regression (GSR): Extends SR shrinking along multiple directions based data. directions usually chosen leading principal components design matrix. Provides adaptive regularization settings collinearity factor structure. Shrinkage Estimator (Sh): Uses non-diagonal shrinkage matrix derived solving Sylvester equation. Applies shrinkage transforming OLS estimator matrix minimizes MSE. Included \"Sh\" specified model_class argument.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm.fit2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Linear Models Fitting with Slab and Shrinkage Estimators — savvy_glm.fit2","text":"custom optimization methods used function designed improve convergence properties GLM fitting process. Marschner, .C. (2011) glm2: Fitting generalized linear models convergence problems. R Journal, Vol. 3/2, pp.12-15.","code":""},{"path":[]},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm.fit2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized Linear Models Fitting with Slab and Shrinkage Estimators — savvy_glm.fit2","text":"Ziwei Chen Vali Asimit Maintainer: Ziwei Chen <ziwei.chen.3@citystgeorges.ac.uk>","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Linear Models with Slab and Shrinkage Estimators — savvy_glm2","title":"Generalized Linear Models with Slab and Shrinkage Estimators — savvy_glm2","text":"savvy_glm2 modified version glm2 stats package, incorporating custom optimization methods. function aims improve convergence properties selecting best fitting method based Akaike Information Criterion (AIC). addition, user can choose run specific shrinkage method providing value model_class argument. single value provided, method executed. multiple values given (default used), function evaluates specified methods parallel returns one lowest AIC.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Linear Models with Slab and Shrinkage Estimators — savvy_glm2","text":"","code":"savvy_glm2(formula, family = gaussian, data, weights,                model_class = c(\"St\", \"DSh\", \"SR\", \"GSR\"), subset,                na.action, start = NULL, etastart, mustart, offset,                control = list(...), model = TRUE,                method = \"savvy_glm.fit2\", x = FALSE, y = TRUE,                contrasts = NULL, ...)"},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Linear Models with Slab and Shrinkage Estimators — savvy_glm2","text":"formula object class \"formula\": symbolic description model fitted. glm. family description error distribution link function used model. glm. data optional data frame, list environment containing variables model. glm. weights optional vector weights used fitting process. glm. model_class character vector specifying shrinkage model(s) used underlying fitter savvy_glm.fit2. Allowed values \"St\", \"DSh\", \"SR\", \"GSR\", \"Sh\". single value provided, method run. multiple values provided (default used), function evaluates specified methods parallel returns one lowest AIC. user explicitly supply value, default c(\"St\", \"DSh\", \"SR\", \"GSR\"), additional method \"Sh\" considered. subset optional vector specifying subset observations used fitting process. glm. na.action function indicates happen data contain NAs. glm. start Starting values parameters linear predictor. glm. etastart Starting values linear predictor. glm. mustart Starting values vector means. glm. offset optional vector specifying priori known component included linear predictor fitting. glm. control list control parameters pass iterative fitting process. glm. model logical value indicating whether model frame included component returned value. glm. method method used fitting model. default savvy_glm.fit2. method uses iteratively reweighted least squares (IRLS) custom optimization methods ensure better convergence evaluating different fitting methods selecting best one based AIC. glm, alternative method \"model.frame\" returns model frame fitting. x logical value indicating whether model matrix used fitting process returned component returned value. glm. y logical value indicating whether response vector used fitting process returned component returned value. glm. contrasts optional list. See contrasts.arg model.matrix.default. glm. ... Additional arguments passed low level regression fitting functions. glm. savvy_glm2 extends glm2 function using custom optimization methods improve convergence properties iteratively reweighted least squares (IRLS) algorithm. function evaluates four custom optimization methods: St_ost, DSh_ost, SR_ost, GSR_ost. user can also include additional method Sh_ost explicitly specifying \"Sh\" model_class argument. fitting process starts initial parameter values iterates IRLS algorithm. iteration, coefficients computed using specified custom methods. final model chosen one lowest AIC, ensuring model converges best possible solution given data specified family.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Linear Models with Slab and Shrinkage Estimators — savvy_glm2","text":"value returned savvy_glm2 exactly structure returned glm, except : method name fitter function used, default savvy_glm.fit2. chosen_fit name chosen fitting method based AIC.","code":""},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Linear Models with Slab and Shrinkage Estimators — savvy_glm2","text":"custom optimization methods used function designed improve convergence properties GLM fitting process. Marschner, .C. (2011) glm2: Fitting generalized linear models convergence problems. R Journal, Vol. 3/2, pp.12-15. savvy_glm2 uses code glm2, whose authors listed help documentation stats package.","code":""},{"path":[]},{"path":"https://Ziwei-ChenChen.github.io/savvyGLM/reference/savvy_glm2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized Linear Models with Slab and Shrinkage Estimators — savvy_glm2","text":"Ziwei Chen Vali Asimit Maintainer: Ziwei Chen <ziwei.chen.3@citystgeorges.ac.uk>","code":""}]
